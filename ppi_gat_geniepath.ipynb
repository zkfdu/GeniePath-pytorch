{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn import metrics\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'\n",
    "\n",
    "path = osp.join('./', 'data', 'PPI')\n",
    "train_dataset = PPI(path, split='train')\n",
    "val_dataset = PPI(path, split='test')\n",
    "test_dataset = PPI(path, split='test')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GATConv(train_dataset.num_features, 256, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(train_dataset.num_features, 4 * 256)\n",
    "        self.conv2 = GATConv(4 * 256, 256, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4 * 256, 4 * 256)\n",
    "        self.conv3 = GATConv(\n",
    "            4 * 256, train_dataset.num_classes, heads=6, concat=False)\n",
    "        self.lin3 = torch.nn.Linear(4 * 256, train_dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        num_graphs = data.num_graphs\n",
    "        data.batch = None\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_op(model(data.x, data.edge_index), data.y)\n",
    "        total_loss += loss.item() * num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_micro_f1 = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x.to(device), data.edge_index.to(device))\n",
    "        pred = (out > 0).float().cpu()\n",
    "        micro_f1 = metrics.f1_score(data.y, pred, average='micro')\n",
    "        total_micro_f1 += micro_f1 * data.num_graphs\n",
    "    return total_micro_f1 / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    acc = test(val_loader)\n",
    "    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geniepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.5599, Acc: 0.5246\n",
      "Epoch: 02, Loss: 0.5193, Acc: 0.4775\n",
      "Epoch: 03, Loss: 0.4960, Acc: 0.5434\n",
      "Epoch: 04, Loss: 0.4682, Acc: 0.6112\n",
      "Epoch: 05, Loss: 0.4343, Acc: 0.6603\n",
      "Epoch: 06, Loss: 0.3909, Acc: 0.7139\n",
      "Epoch: 07, Loss: 0.3387, Acc: 0.7550\n",
      "Epoch: 08, Loss: 0.2975, Acc: 0.7963\n",
      "Epoch: 09, Loss: 0.2538, Acc: 0.8209\n",
      "Epoch: 10, Loss: 0.2412, Acc: 0.8349\n",
      "Epoch: 11, Loss: 0.2195, Acc: 0.8512\n",
      "Epoch: 12, Loss: 0.1976, Acc: 0.8769\n",
      "Epoch: 13, Loss: 0.1686, Acc: 0.8898\n",
      "Epoch: 14, Loss: 0.1641, Acc: 0.8859\n",
      "Epoch: 15, Loss: 0.1546, Acc: 0.9012\n",
      "Epoch: 16, Loss: 0.1360, Acc: 0.9172\n",
      "Epoch: 17, Loss: 0.1207, Acc: 0.9168\n",
      "Epoch: 18, Loss: 0.1191, Acc: 0.9242\n",
      "Epoch: 19, Loss: 0.1124, Acc: 0.9285\n",
      "Epoch: 20, Loss: 0.1064, Acc: 0.9242\n",
      "Epoch: 21, Loss: 0.1062, Acc: 0.9330\n",
      "Epoch: 22, Loss: 0.1036, Acc: 0.9304\n",
      "Epoch: 23, Loss: 0.1001, Acc: 0.9294\n",
      "Epoch: 24, Loss: 0.1060, Acc: 0.9211\n",
      "Epoch: 25, Loss: 0.1086, Acc: 0.9282\n",
      "Epoch: 26, Loss: 0.0944, Acc: 0.9356\n",
      "Epoch: 27, Loss: 0.0976, Acc: 0.9350\n",
      "Epoch: 28, Loss: 0.0943, Acc: 0.9363\n",
      "Epoch: 29, Loss: 0.0965, Acc: 0.9368\n",
      "Epoch: 30, Loss: 0.1025, Acc: 0.9175\n",
      "Epoch: 31, Loss: 0.1150, Acc: 0.9330\n",
      "Epoch: 32, Loss: 0.0985, Acc: 0.9343\n",
      "Epoch: 33, Loss: 0.0944, Acc: 0.9382\n",
      "Epoch: 34, Loss: 0.0815, Acc: 0.9460\n",
      "Epoch: 35, Loss: 0.0783, Acc: 0.9421\n",
      "Epoch: 36, Loss: 0.0912, Acc: 0.9333\n",
      "Epoch: 37, Loss: 0.0982, Acc: 0.9393\n",
      "Epoch: 38, Loss: 0.0863, Acc: 0.9422\n",
      "Epoch: 39, Loss: 0.0995, Acc: 0.9228\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn import metrics\n",
    "\n",
    "# from model_geniepath import GeniePath as Net\n",
    "from model_geniepath import GeniePathLazy as Net\n",
    "\n",
    "path = osp.join('./', 'data', 'PPI')\n",
    "train_dataset = PPI(path, split='train')\n",
    "val_dataset = PPI(path, split='test')\n",
    "test_dataset = PPI(path, split='test')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_features, train_dataset.num_classes, device).to(device)\n",
    "loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        num_graphs = data.num_graphs\n",
    "        data.batch = None\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_op(model(data.x, data.edge_index), data.y)\n",
    "        total_loss += loss.item() * num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_micro_f1 = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x.to(device), data.edge_index.to(device))\n",
    "        pred = (out > 0).float().cpu()\n",
    "        micro_f1 = metrics.f1_score(data.y, pred, average='micro')\n",
    "        total_micro_f1 += micro_f1 * data.num_graphs\n",
    "    return total_micro_f1 / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    acc = test(val_loader)\n",
    "    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import AGNNConv\n",
    "\n",
    "dataset = 'Cora'\n",
    "path = osp.join( './', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "# path = osp.join('./', 'data', 'PPI')\n",
    "# train_dataset = PPI(path, split='train')\n",
    "# val_dataset = PPI(path, split='test')\n",
    "# test_dataset = PPI(path, split='test')\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(dataset.num_features, 16)\n",
    "        self.prop1 = AGNNConv(requires_grad=False)\n",
    "        self.prop2 = AGNNConv(requires_grad=True)\n",
    "        self.lin2 = torch.nn.Linear(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self):\n",
    "        x = F.dropout(data.x, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.prop1(x, data.edge_index)\n",
    "        x = self.prop2(x, data.edge_index)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_acc, best_val_acc, test_acc))\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py77] *",
   "language": "python",
   "name": "conda-env-py77-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
